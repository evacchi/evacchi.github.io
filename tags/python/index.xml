<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Python on Middle of Nowhere</title><link>/tags/python/</link><description>Recent content in Python on Middle of Nowhere</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Wed, 07 Oct 2015 12:00:00 +0000</lastBuildDate><atom:link href="/tags/python/index.xml" rel="self" type="application/rss+xml"/><item><title>Python for Data Science</title><link>/posts/2015/10/07/python-for-data-science/</link><pubDate>Wed, 07 Oct 2015 12:00:00 +0000</pubDate><guid>/posts/2015/10/07/python-for-data-science/</guid><description>These are the slides for a talk I gave recently.
Abstract. IPython notebooks, NumPy and Pandas data frames are the go-to tools for doing data science with Python. Spark and PySpark is rapidly becoming the de facto standard for doing analysis on large volumes of data. But what about CPU-intensive tasks? What about rough numerical, but distributed computations? In the first part of this talk I give an overview of the most interesting alternatives.</description></item></channel></rss>